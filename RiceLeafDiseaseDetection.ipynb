{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(10)\n",
    "import numpy as np\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OOcg58Urd6Pg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LXoQUyeBo2h4"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0I_FgKYcslr"
   },
   "source": [
    "checking each folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C5Hy_AOSbhuD",
    "outputId": "077ad42d-7403-4e58-abbe-fc170d40fa8f"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\new\\\\Downloads\\\\PRCP-1001-RiceLeaf\\\\data1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnew\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPRCP-1001-RiceLeaf\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata1\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\new\\\\Downloads\\\\PRCP-1001-RiceLeaf\\\\data1'"
     ]
    }
   ],
   "source": [
    "print(os.listdir(r'C:\\Users\\new\\Downloads\\PRCP-1001-RiceLeaf\\data1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Utm-k66Wckka",
    "outputId": "af7604cc-c76e-4b4d-9f09-968a61c9e50c"
   },
   "outputs": [],
   "source": [
    "print(os.listdir(r'C:\\Users\\new\\Downloads\\PRCP-1001-RiceLeaf\\data1\\Bacterial leaf blight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u3cOc6HLc7va",
    "outputId": "cf7fa744-37ab-446b-bc29-1dbd031a0567"
   },
   "outputs": [],
   "source": [
    "print((os.listdir(r'C:\\Users\\new\\Downloads\\PRCP-1001-RiceLeaf\\data1\\Brown spot')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((os.listdir(r'C:\\Users\\new\\Downloads\\PRCP-1001-RiceLeaf\\data1\\leaf smut')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZz1ZHGJiu3v"
   },
   "source": [
    "checking the no. of images in each classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GeAoVmqndo68",
    "outputId": "92fe2515-cbe2-4d7f-b897-6b9411bdb542"
   },
   "outputs": [],
   "source": [
    "#Bacterial leaf blight\n",
    "print(len(os.listdir(r'C:\\Users\\new\\Downloads\\PRCP-1001-RiceLeaf\\data1\\Bacterial leaf blight')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D8PTEy2uihN4",
    "outputId": "70ac5c04-911f-42bb-f7fb-95ffb071f517"
   },
   "outputs": [],
   "source": [
    "# Brown spot\n",
    "print(len(os.listdir(r'C:\\Users\\new\\Downloads\\PRCP-1001-RiceLeaf\\data1\\Brown spot')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1e-bSthwilmZ",
    "outputId": "325de6d6-b0f9-4256-d5b6-6dce0a4cb7c5"
   },
   "outputs": [],
   "source": [
    "#Leaf smut\n",
    "print(len(os.listdir(r'C:\\Users\\new\\Downloads\\PRCP-1001-RiceLeaf\\data1\\leaf smut')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RE_Ji9DVWg7j"
   },
   "source": [
    "here Bacterial leaf blight and Brown spot contain 40 images each, while leaf smut contains only 39 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xPvQccUlywu"
   },
   "source": [
    "visualizing the images in each classes and checking the image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pillow\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "id": "jjc7fRBqoJBx",
    "outputId": "95bff53f-57df-4318-c606-1e51a57fd2e8"
   },
   "outputs": [],
   "source": [
    "data_paths = {\n",
    "    \"Bacterial leaf blight\": r'C:\\Users\\new\\Downloads\\PRCP-1001-RiceLeaf\\data1\\Bacterial leaf blight',\n",
    "    \"Brown spot\": r'C:\\Users\\new\\Downloads\\PRCP-1001-RiceLeaf\\data1\\Brown spot' ,\n",
    "    \"Leaf smut\": r'C:\\Users\\new\\Downloads\\PRCP-1001-RiceLeaf\\data1\\leaf smut'\n",
    "}\n",
    "\n",
    "# Number of images to display from each path\n",
    "num_images_to_display = 10\n",
    "\n",
    "# Loop through each path and category name\n",
    "for category_name, path in data_paths.items(): # Iterate through the dictionary items to get both key and value\n",
    "    # Get a list of image files in the path\n",
    "    image_files = [f for f in os.listdir(path) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "\n",
    "\n",
    "    # Display the selected images\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(path, image_file)\n",
    "        img = mpimg.imread(image_path)\n",
    "        print(img.shape)\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "        # Get image format\n",
    "        print(\"Image Format:\", img.format)\n",
    "        plt.imshow(img)\n",
    "        plt.title(category_name)  # Optionally display the image filename as the title\n",
    "        plt.axis('off')  # Turn off axis ticks and labels\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcCh2RV00uaZ"
   },
   "source": [
    "Most of the images in 'Bacterial leaf blight' are of same size ,Image shape: (897, 3081, 3).\n",
    "But i can see the size vary in 'Brown spot' and ' Leaf smut'. some are of like  (88, 296, 3), (168, 359, 3),(323, 1504, 3)  and so on in Brown spot.\n",
    "and in Leaf smut sizes of some images are like (73, 367, 3),(174, 503, 3) ,(897, 3081, 3). All images are of JPEG format.\n",
    "So, we need to resize the images to the same size. Let's resize them to (224, 224, 3) so that the image dimensions are not too large and it doesn't take up excessive memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OytcuZADUZDt"
   },
   "outputs": [],
   "source": [
    "CATEGORIES=['Bacterial leaf blight','Brown spot','Leaf smut']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mAv6ILQHlQPq"
   },
   "source": [
    "This dataset contains 119 images of rice leaf (JPEG).  These are grouped into 3 different folders according to disease type 'Bacterial leaf blight','Brown spot','Leaf smut'.\n",
    "So we are creating an array called training[] to store images that are resized to (224,224,3) and the index at which the image in the CATEGORIES list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbN4yWsgUZAw"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "training = []  #Training is an array that will contain image pixel values and the index at which the image in the CATEGORIES list.\n",
    "datapath= r'C:\\Users\\new\\Downloads\\PRCP-1001-RiceLeaf\\data1'\n",
    "def createTrainingData():  # creating function\n",
    "  for category in CATEGORIES:\n",
    "    path = os.path.join(datapath, category)\n",
    "    class_num = CATEGORIES.index(category)\n",
    "    for img in os.listdir(path):\n",
    "      img_array = cv2.imread(os.path.join(path,img))\n",
    "      new_array = cv2.resize(img_array, (512\n",
    "                                         , 512)) # i am resizing all images to 512x512\n",
    "      training.append([new_array, class_num])\n",
    "createTrainingData() # calling the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvrZoO5OlEes"
   },
   "source": [
    "shuffling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsxyzyX9UY9z"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWHR45orlBNa"
   },
   "source": [
    " Assigning Labels and Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mnu7ZUAjUY7D"
   },
   "outputs": [],
   "source": [
    "X =[]\n",
    "y =[]\n",
    "for features, label in training:\n",
    "  X.append(features)\n",
    "  y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNjRayLQnpZy"
   },
   "outputs": [],
   "source": [
    "X = np.array(X)  #  reshaping  list of images (X) into a 4D NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_siVX7ccUY4F",
    "outputId": "6b7961a1-81a2-4c69-a589-c73630361160"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(X[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "k4J3R9OWZN4h",
    "outputId": "67e092b6-7d50-49b3-a169-b750232fda71"
   },
   "outputs": [],
   "source": [
    "#visualizing first 10 resized images in X\n",
    "plt.figure(figsize=(10,5))\n",
    "plotnum=1\n",
    "\n",
    "for i in range(0,10):\n",
    "  plt.subplot(2,5,plotnum)\n",
    "  plotnum+=1\n",
    "\n",
    "  plt.imshow(X[i])\n",
    "  plt.title(y[i])\n",
    "  plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qchry7TDUY01",
    "outputId": "8fbabcaa-5c44-46f3-abe5-902cd9f942cf"
   },
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7yfN7j6IUYtc",
    "outputId": "bb879438-bd4c-4707-8ca3-6fe8fe493ef0"
   },
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BkQPTfVhoKs4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAASThDooLRR"
   },
   "source": [
    "Normalising X and OneHotEncoding on converted labels 0,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F2CrYpCOUYqR",
    "outputId": "f339a1a1-f39a-4cbe-b2aa-fb041d9dfd3d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "X = X.astype('float32')\n",
    "X /= 255\n",
    "\n",
    "Y = to_categorical(y, 3)\n",
    "\n",
    "# to_categorical is a function used to convert categorical class labels (e.g., integers like 0, 1, 2) into one-hot encoded vectors.\n",
    "# For example, the class 0 would be converted to [1, 0, 0], class 1 to [0, 1, 0], etc.\n",
    "# This is necessary for classification problems where each class is represented by a vector in the output layer of a neural network.\n",
    "\n",
    "print(Y[100]) # printing 100th element in Y\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y2ywHcyPriXs",
    "outputId": "ee1df283-d0c3-4919-ca83-7b9a77a6cbf9"
   },
   "outputs": [],
   "source": [
    "print(X[:1])\n",
    "print(Y[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting dataset into training, validation and test ore. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation set is a set of data, separate from the training set, that is used to validate our model performance during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This validation process gives information that helps us tune the model’s hyperparameters and configurations accordingly. It is like a critic telling us whether the training is moving in the right direction or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained on the training set, and, simultaneously, the model evaluation is performed on the validation set after every epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea of splitting the dataset into a validation set is to prevent our model from overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fq05eojUUYnL"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split the data into training(here temp) and testing dataset. we are splitting in 80%,20% for training AND TESTING\n",
    "X_temp, X_test, Y_temp, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YEODKe2I8CEB",
    "outputId": "48a1bd3b-bcd7-4794-9e48-03720be4c2e5"
   },
   "outputs": [],
   "source": [
    "print(len(X_temp))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddVfXsZV97H5"
   },
   "outputs": [],
   "source": [
    "# break training set into training and validation sets\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size = 0.1, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iKO9l2xP79T7",
    "outputId": "3562a8cc-6a18-4067-b2d7-12ac878b78ca"
   },
   "outputs": [],
   "source": [
    "# print number of training, validation, and test images\n",
    "print(len(X_train), 'train samples')\n",
    "print(len(X_test), 'test samples')\n",
    "print(len(X_val), 'validation samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSRIzd77UYdU"
   },
   "source": [
    "### creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KfzGG7akUYX8"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential #import\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential() #This initializes an empty model. You will add layers to this model one by one.\n",
    "\n",
    "#creating 3 convolution layers\n",
    "model.add(Conv2D(filters=8, kernel_size=2, padding='same', activation='relu',\n",
    "                        input_shape=(512, 512, 3)))   # using 8 filters in 1st convolution layer, so the output will have 8 feature maps. Fewer filters mean fewer features are detected,\n",
    "                                                      # and thus fewer parameters are learned.\n",
    "                                                     # kernal_size is 2x2\n",
    "                                                    # padding='same' means that the output feature map will have the same width and height as the input. \n",
    "                                                     #input shape is the shape of input image. we had resized it to (224,224,3)\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=2))  # Pooling is a downsampling operation that reduces the spatial dimensions (height and width) of the input,\n",
    "                                      #typically by selecting the maximum value from a set of pixels within a small region.\n",
    "                        #for each 2x2 region in the input, the max pooling operation will select the maximum value from that region, effectively reducing the size of the feature map.\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(3, activation='softmax'))   # 3 classes\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTjeLtHAUYRF"
   },
   "source": [
    "### Total params: 6,556,515 is the total no. of parameters which includes both weights and bias in our model.\n",
    "### *Model Complexity: The number of parameters indicates how complex our model is. A model with more parameters has greater capacity to learn intricate patterns, but it also requires more data and computational power to train effectively.\n",
    "\n",
    "### *Overfitting Risk: A large number of parameters can increase the risk of overfitting, especially if the dataset is small. In this case, our model might \"memorize\" the training data instead of learning generalizable patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uaLDAaoUYK8"
   },
   "source": [
    "# compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2Bcp8SjcN2V"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#categorical_crossentropy -- calc the error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8tc1xxd9yWL"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()  # Get current working directory\n",
    "print(\"Current Working Directory:\", cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIga4c_Ypot2"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='saved_model/model.weights.best.keras', save_best_only=True)\n",
    "\n",
    "hist = model.fit(X_train, Y_train, batch_size=10, epochs=30,\n",
    "        validation_data=(X_val, Y_val),callbacks=[checkpointer],verbose=1,\n",
    "           shuffle=True)\n",
    "#epoch --the number times that the learning algorithm will work through the entire training dataset\n",
    "#batch_size -- how many samples for each iteration, When the batch size is set to 32, it means that during \n",
    "#               each iteration of training, the neural network processes 32 examples (data points) at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uF5CsXZu7zVo"
   },
   "outputs": [],
   "source": [
    "# get predictions on the test set\n",
    "y_hat = model.predict(X_test)\n",
    "print(y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKc9emqb8vhO"
   },
   "outputs": [],
   "source": [
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# print test accuracy\n",
    "print('Test accuracy: %.4f%%' % accuracy)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hiJlJZ4eLrl5"
   },
   "outputs": [],
   "source": [
    "# evaluate training accuracy\n",
    "score_train = model.evaluate(X_train, Y_train, verbose=0)\n",
    "accuracy_train = 100 * score_train[1]\n",
    "\n",
    "# print training accuracy\n",
    "print('Training accuracy: %.4f%%' % accuracy_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PDpsEZf6LOha"
   },
   "source": [
    "#### so the model is overfitting here. Let us apply data augmentation on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3t4DvWGLR8s"
   },
   "source": [
    "Data augmentation is a technique of artificially increasing the training set by creating modified copies of a dataset using existing data.\n",
    "\n",
    "Data augmentation is particularly useful here since we have:\n",
    "\n",
    "limited amount of data.\n",
    "To reduce overfitting.\n",
    "to increase the diversity of your dataset to avoid overfitting.\n",
    "to simulate different real-world scenarios (such as varying lighting, orientation, and zoom).\n",
    "\n",
    "\n",
    "Augmentation techniques:\n",
    "\n",
    "rotation_range: Randomly rotate the images by up to the specified degrees.\n",
    "width_shift_range and height_shift_range: Randomly shift the image horizontally or vertically by up to the given fraction of the image's width or height.\n",
    "shear_range: Applies a shear transformation to images.\n",
    "zoom_range: Randomly zooms into images.\n",
    "horizontal_flip: Flips images horizontally with a 50% chance.\n",
    "fill_mode: Defines how to fill pixels that are shifted or rotated (e.g., using 'nearest' or 'constant').\n",
    "\n",
    "flow() Method: The flow() method will return batches of augmented images and labels in each iteration. The argument batch_size defines the number of images to return per batch.\n",
    "\n",
    "Training with Augmented Data: You can pass the train_generator directly to model.fit() to train your model. The generator will provide augmented data on the fly during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of X_train, X_val, and X_test\n",
    "print('Shape of X_train:', X_train.shape)\n",
    "print('Shape of X_val:', X_val.shape)\n",
    "print('Shape of X_test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2LWg6h9ApLX",
    "outputId": "af298af9-6820-4006-c4b7-e03252f35c1e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X is your image data (shape: [num_samples, 512, 512, 3])\n",
    "# and Y is your one-hot encoded labels (shape: [num_samples, 3])\n",
    "\n",
    "# Step 1: Create the ImageDataGenerator with augmentations\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,        # Random rotations from -20 to 20 degrees\n",
    "    width_shift_range=0.2,    # Random horizontal shifts\n",
    "    height_shift_range=0.2,   # Random vertical shifts\n",
    "    shear_range=0.2,          # Random shearing transformation(tilting the image across the axis)\n",
    "    zoom_range=0.2,           # Random zoom\n",
    "    horizontal_flip=True,     # Random horizontal flip(mirror image)\n",
    "    fill_mode='nearest' ,  # How to fill pixels after transformations\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "# Step 3: Fit the generators on the data \n",
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_generator = train_datagen.flow(X_train, Y_train, batch_size=32)\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Step 5: Train the model using the generators\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(X_train) // 32,\n",
    "    epochs=30,\n",
    "    validation_data=(X_val, Y_val), # Directly pass validation data\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate the model's performance on test data\n",
    "score_test = model.evaluate(X_test, Y_test, verbose=2)\n",
    "accuracy_test = 100 * score_test[1]\n",
    "print('Test accuracy: %.4f%%' % accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate training accuracy\n",
    "score_train = model.evaluate(X_train, Y_train, verbose=0)\n",
    "accuracy_train = 100 * score_train[1]\n",
    "\n",
    "# print training accuracy\n",
    "print('Training accuracy: %.4f%%' % accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# If y_true and y_pred are one-hot encoded or probabilities, convert to class labels\n",
    "Y_test_class = np.argmax(Y_test, axis=1)  # Convert one-hot encoded true labels\n",
    "y_pred_class = np.argmax(y_hat, axis=1)  # Convert predicted probabilities to class labels\n",
    "\n",
    "# Now you can use classification_report\n",
    "print(classification_report(Y_test_class, y_pred_class))\n",
    "print(confusion_matrix(Y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "zKpr9bKU-igy",
    "outputId": "5a9f87b3-e361-4323-efb2-7273f0392c13"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    r\"C:\\Users\\new\\Downloads\\5426924lgpt.jpg\", target_size=(512,512,3) # passing new googled image of brownspot disease.\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "score = predictions[0]\n",
    "score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting all the predicted Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8M-KedSuAqyr",
    "outputId": "cbd1264e-c79e-4a9b-ea31-3fb17d2cb38f"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40, 13))\n",
    "for i, idx in enumerate(range(X_test.shape[0])):  # Iterate over all test images\n",
    "    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(X_test[idx]))\n",
    "    pred_idx = np.argmax(y_hat[idx])\n",
    "    true_idx = np.argmax(Y_test[idx])\n",
    "    ax.set_title(\"{} ({})\".format(CATEGORIES[pred_idx], CATEGORIES[true_idx]),\n",
    "                 color=(\"blue\" if pred_idx == true_idx else \"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "91pqG-fwAwRY",
    "outputId": "2847499e-0162-4b51-8c53-7c0b6b57f099"
   },
   "source": [
    "# Report on Rice Leaf Disease Detection Using Data Augmentation and Model Optimization Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4xrth8g_MOAq",
    "outputId": "37923c22-641a-494e-ced0-e9b749dce973"
   },
   "source": [
    "Data augmentation is an essential technique in deep learning, especially when working with a limited dataset. By artificially increasing the size of the training set, augmentation helps the model generalize better, improving its performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SwWo2XWZL-Dq",
    "outputId": "4a116b96-8fc6-4067-83f8-0aa604030e86"
   },
   "source": [
    "Given the limited size of the dataset (119 images), we explored several techniques, including Data Augmentation, to enhance model performance and avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OT7onXyUIgTs"
   },
   "source": [
    "### Techniques applied\n",
    "--------------------------\n",
    "#### Rotation:\n",
    "First I rotated the image by 10 degrees, but it was not reducing the overfitting that much.\n",
    "Then I tried 20 degrees.That not only increased the testing accuracy but also reduced the overfitting.\n",
    "\n",
    "#### Shearing:\n",
    "Random shearing transformations that tilt the images along the X or Y axis.\n",
    "Helps the model recognize leaves under different perspectives.\n",
    "first I started with giving value o.1. but changing it to 0.2 improved the accuracy\n",
    "\n",
    "#### Zoom:\n",
    "Random zooming in or out of the images.\n",
    "Mimics varying distances and focal lengths.\n",
    "\n",
    "#### Horizontal Flip:\n",
    "Randomly flipping images horizontally.\n",
    "Ensures the model does not become biased by orientation.\n",
    "\n",
    "#### Fill Mode:\n",
    "The nearest fill mode was used to fill in missing pixel areas after transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zyoe3F7IJO3l",
    "outputId": "2afbd8d7-d7a3-4d11-906e-4c46366408ff"
   },
   "source": [
    "### Impact of Augmentation\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F49HMkpRJWya",
    "outputId": "1bf54118-8838-4a36-aef8-1bfa3005cf1f"
   },
   "source": [
    "I trained two models for comparison:\n",
    "\n",
    "Model 1: Trained on the original dataset without augmentation.\n",
    "Model 2: Trained on the dataset with augmentation techniques applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbG7MZQINIa_"
   },
   "source": [
    "Model 1 (No Augmentation):\n",
    "Training Accuracy: 100%\n",
    "Test Accuracy: 79.1%\n",
    "\n",
    "Model 2 (With Augmentation):\n",
    "Training Accuracy: 98%\n",
    "Test Accuracy: 87.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSoq0gjfQg9m"
   },
   "source": [
    "The performance improvement from 79.1% to 87.5% test accuracy suggests that data augmentation helped the model generalize better, making it less prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting the augmented images of an image taken from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original image\n",
    "from tensorflow.keras.preprocessing.image import  load_img,img_to_array\n",
    "img_path = r'C:\\Users\\new\\Downloads\\PRCP-1001-RiceLeaf\\data1\\Brown spot\\DSC_0100.jpg'  # Provide the path to your image\n",
    "img = load_img(img_path)  # Load the image as PIL format\n",
    "\n",
    "# Convert image to numpy array\n",
    "img_array = img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "\n",
    "\n",
    "# Create an iterator for generating augmented images\n",
    "augmented_images = train_datagen.flow(img_array, batch_size=1)\n",
    "\n",
    "# Plot the original image and augmented images\n",
    "fig, ax = plt.subplots(1, 7, figsize=(20, 5))\n",
    "\n",
    "# Display the original image\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "# Display 4 augmented images\n",
    "for i in range(1, 7):\n",
    "    augmented_image = next(augmented_images)[0].astype('uint8')  # Generate augmented image\n",
    "    ax[i].imshow(augmented_image)\n",
    "    ax[i].set_title(f'Augmented Image {i}')\n",
    "    ax[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDMv-55YRdm4"
   },
   "source": [
    "\n",
    "###  Additional Techniques\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZAkk2z_SRt3n",
    "outputId": "67e430c8-8de7-4b6a-bab8-3e6ea6e8aadd"
   },
   "source": [
    "#### Image Preprocessing:\n",
    "I normalized the pixel values to the range [0, 1] for consistency and to ensure faster convergence during training. Image normalization helps models train faster and more efficiently by scaling the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zD5IWBk5Ryfx"
   },
   "source": [
    "#### Model Optimization:\n",
    "\n",
    "Batch Size: I experimented with different batch sizes (32 and 50) to determine the best balance between computational efficiency and model accuracy. A batch size of 32 was optimal for this dataset.\n",
    "\n",
    "Epochs: I trained the model for 30 epochs, which allowed it to converge while avoiding overfitting.\n",
    "\n",
    "Early Stopping: Had to apply early stopping during the training process. This technique helps in halting the training when the validation loss stops improving, preventing unnecessary overfitting. By monitoring the validation loss, early stopping ensures that the model does not continue to learn from noise in the training data once the model's performance on the validation set starts to degrade, improving generalization on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_GWxystR22_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## challenges faced in this project:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limited no. of Images in the dataset:\n",
    "With only 119 images in the dataset we cant train the deep learning model effectively. In deep learning, the model requires large no. of images in the dataset. And we resolved issue by applying data augmentation.\n",
    "\n",
    "### Images were of different size:\n",
    "most deep learning models require input images to have a consistent shape and dimension for efficient processing. To handle this, we did resizing technique to resize it to same size and shape( here we converted it into 512x512x3) before passing it to the model. And we normalized the images by dividing it by 255.\n",
    "\n",
    "### overfitting:\n",
    "model without augmentation was overfitting and we reduced it by applying augmentation . so the model with augmentation was the better model to use for production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
